# Alerting Strategy - å‘Šè­¦ç­–ç•¥è®¾è®¡

**ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2026-01-07
**ç»´æŠ¤äºº**: yangyangyang

---

## ç›®å½•

- [1. å‘Šè­¦ä½“ç³»](#1-å‘Šè­¦ä½“ç³»)
- [2. å‘Šè­¦è§„åˆ™](#2-å‘Šè­¦è§„åˆ™)
- [3. å‘Šè­¦è·¯ç”±](#3-å‘Šè­¦è·¯ç”±)
- [4. å‘Šè­¦æŠ‘åˆ¶](#4-å‘Šè­¦æŠ‘åˆ¶)
- [5. å‘Šè­¦é€šçŸ¥](#5-å‘Šè­¦é€šçŸ¥)
- [6. åº”æ€¥å“åº”](#6-åº”æ€¥å“åº”)
- [7. å®Œæ•´é…ç½®](#7-å®Œæ•´é…ç½®)

---

## 1. å‘Šè­¦ä½“ç³»

### 1.1 å‘Šè­¦æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              1. è§¦å‘æ¡ä»¶æ»¡è¶³                          â”‚
â”‚         (Prometheus è¯„ä¼°å‘Šè­¦è§„åˆ™)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              2. å‘Šè­¦ç”Ÿæˆ                             â”‚
â”‚         (Alertmanager æ¥æ”¶å‘Šè­¦)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              3. å‘Šè­¦å»é‡å’Œåˆ†ç»„                        â”‚
â”‚         (alertmanager/alerts.go)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              4. å‘Šè­¦è·¯ç”±                             â”‚
â”‚         (åŒ¹é…è·¯ç”±è§„åˆ™)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              5. å‘Šè­¦æŠ‘åˆ¶                             â”‚
â”‚         (æ£€æŸ¥æŠ‘åˆ¶è§„åˆ™)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              6. å‘Šè­¦é™é»˜                             â”‚
â”‚         (æ£€æŸ¥é™é»˜è§„åˆ™)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              7. å‘é€é€šçŸ¥                             â”‚
â”‚         (é‚®ä»¶/çŸ­ä¿¡/IM/ç”µè¯)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 å‘Šè­¦çº§åˆ«

| çº§åˆ« | åç§° | å“åº”æ—¶é—´ | å‡çº§æ—¶é—´ | é€šçŸ¥æ–¹å¼ | ç¤ºä¾‹ |
|------|------|----------|----------|----------|------|
| **P0** | ç´§æ€¥ | 5 åˆ†é’Ÿ | 15 åˆ†é’Ÿ | ç”µè¯ + çŸ­ä¿¡ + IM | æœåŠ¡å®Œå…¨ä¸å¯ç”¨ |
| **P1** | ä¸¥é‡ | 15 åˆ†é’Ÿ | 1 å°æ—¶ | çŸ­ä¿¡ + IM | æ ¸å¿ƒåŠŸèƒ½å¼‚å¸¸ |
| **P2** | è­¦å‘Š | 1 å°æ—¶ | 4 å°æ—¶ | IM + é‚®ä»¶ | æ€§èƒ½ä¸‹é™ |
| **P3** | æç¤º | 1 å¤© | - | é‚®ä»¶ | èµ„æºä½¿ç”¨ç‡é«˜ |

### 1.3 å‘Šè­¦åˆ†ç±»

**æŒ‰æ¥æºåˆ†ç±»**ï¼š
- **åº”ç”¨å‘Šè­¦**ï¼šæœåŠ¡ä¸å¯ç”¨ã€é”™è¯¯ç‡è¿‡é«˜
- **ä¸šåŠ¡å‘Šè­¦**ï¼šäº¤æ˜“å¤±è´¥ã€æ”¶ç›Šå¼‚å¸¸
- **èµ„æºå‘Šè­¦**ï¼šCPU/å†…å­˜/ç£ç›˜ä¸è¶³
- **å®‰å…¨å‘Šè­¦**ï¼šå¼‚å¸¸ç™»å½•ã€API å¯†é’¥æ³„éœ²

**æŒ‰å½±å“èŒƒå›´åˆ†ç±»**ï¼š
- **å…¨å±€å‘Šè­¦**ï¼šå½±å“æ‰€æœ‰æœåŠ¡ï¼ˆå¦‚æ•°æ®åº“å®•æœºï¼‰
- **æœåŠ¡å‘Šè­¦**ï¼šå½±å“å•ä¸ªæœåŠ¡ï¼ˆå¦‚ Price Monitor å¼‚å¸¸ï¼‰
- **å®ä¾‹å‘Šè­¦**ï¼šå½±å“å•ä¸ªå®ä¾‹ï¼ˆå¦‚æŸä¸ª Pod OOMï¼‰

---

## 2. å‘Šè­¦è§„åˆ™

### 2.1 åº”ç”¨å¯ç”¨æ€§å‘Šè­¦

#### æœåŠ¡ä¸‹çº¿

```yaml
# alerts/application.yml
groups:
  - name: application_availability
    interval: 30s
    rules:
      # æœåŠ¡å®Œå…¨ä¸‹çº¿
      - alert: ServiceDown
        expr: up{job="arbitragex"} == 0
        for: 2m
        labels:
          severity: critical
          level: P0
          category: availability
        annotations:
          summary: "Service {{ $labels.instance }} is down"
          description: "{{ $labels.instance }} has been down for more than 2 minutes"
          runbook_url: "https://docs.arbitragex.com/runbooks/service-down"

      # æœåŠ¡é‡å¯é¢‘ç¹
      - alert: ServiceRestartingTooFrequently
        expr: |
          increase(kube_pod_container_status_restarts_total{namespace="arbitragex"}[1h]) > 5
        for: 5m
        labels:
          severity: warning
          level: P1
          category: availability
        annotations:
          summary: "Pod {{ $labels.pod }} restarting too frequently"
          description: "Pod {{ $labels.pod }} has restarted {{ $value }} times in the last hour"
```

#### é”™è¯¯ç‡è¿‡é«˜

```yaml
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
          /
          sum(rate(http_requests_total[5m])) by (service) > 0.05
        for: 5m
        labels:
          severity: critical
          level: P0
          category: application
        annotations:
          summary: "High error rate on {{ $labels.service }}"
          description: "Error rate is {{ $value | humanizePercentage }} for the last 5 minutes"

      # é”™è¯¯ç‡ä¸Šå‡
      - alert: ErrorRateIncreasing
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
            /
            sum(rate(http_requests_total[5m])) by (service)
          )
          >
          (
            sum(rate(http_requests_total{status=~"5.."}[30m])) by (service)
            /
            sum(rate(http_requests_total[30m])) by (service)
          ) * 1.5
        for: 10m
        labels:
          severity: warning
          level: P1
          category: application
        annotations:
          summary: "Error rate increasing on {{ $labels.service }}"
          description: "Error rate has increased by 50% in the last 10 minutes"
```

#### å»¶è¿Ÿè¿‡é«˜

```yaml
      - alert: HighLatency
        expr: |
          histogram_quantile(0.99,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 1
        for: 5m
        labels:
          severity: warning
          level: P2
          category: performance
        annotations:
          summary: "High latency on {{ $labels.service }}"
          description: "P99 latency is {{ $value }}s for the last 5 minutes"

      # P99 å»¶è¿Ÿè¿‡é«˜ï¼ˆä¸¥é‡ï¼‰
      - alert: CriticalHighLatency
        expr: |
          histogram_quantile(0.99,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 5
        for: 2m
        labels:
          severity: critical
          level: P1
          category: performance
        annotations:
          summary: "Critical high latency on {{ $labels.service }}"
          description: "P99 latency is {{ $value }}s for the last 2 minutes"
```

### 2.2 ä¸šåŠ¡å‘Šè­¦

#### äº¤æ˜“å¤±è´¥ç‡

```yaml
  - name: business_alerts
    interval: 30s
    rules:
      # äº¤æ˜“å¤±è´¥ç‡é«˜
      - alert: HighTradeFailureRate
        expr: |
          sum(rate(trade_executions_total{status="failed"}[10m]))
          /
          sum(rate(trade_executions_total[10m])) > 0.1
        for: 10m
        labels:
          severity: warning
          level: P1
          category: business
        annotations:
          summary: "High trade failure rate"
          description: "Trade failure rate is {{ $value | humanizePercentage }} for the last 10 minutes"

      # äº¤æ˜“é‡ä¸º 0
      - alert: NoTradesExecuted
        expr: |
          sum(increase(trade_executions_total[1h])) == 0
        for: 2h
        labels:
          severity: warning
          level: P2
          category: business
        annotations:
          summary: "No trades executed in the last 2 hours"
          description: "System may not be functioning properly"
```

#### æ”¶ç›Šå¼‚å¸¸

```yaml
      # æ”¶ç›Šä¸ºè´Ÿ
      - alert: NegativeProfit
        expr: |
          rate(total_profit_usd[1h]) < -100
        for: 30m
        labels:
          severity: critical
          level: P0
          category: business
        annotations:
          summary: "Negative profit detected"
          description: "Profit rate is {{ $value }} USD/hour for the last 30 minutes"

      # æ”¶ç›Šä¸‹é™
      - alert: ProfitDeclining
        expr: |
          rate(total_profit_usd[5m])
          <
          rate(total_profit_usd[1h]) * 0.5
        for: 30m
        labels:
          severity: warning
          level: P2
          category: business
        annotations:
          summary: "Profit declining"
          description: "Profit rate has dropped by 50% in the last 30 minutes"
```

#### å¥—åˆ©æœºä¼š

```yaml
      # å¥—åˆ©æœºä¼šè¿‡å°‘
      - alert: FewArbitrageOpportunities
        expr: |
          rate(arbitrage_opportunities_discovered_total[1h]) < 10
        for: 2h
        labels:
          severity: warning
          level: P2
          category: business
        annotations:
          summary: "Very few arbitrage opportunities"
          description: "Only {{ $value }} opportunities/hour in the last 2 hours"
```

### 2.3 èµ„æºå‘Šè­¦

#### CPU ä½¿ç”¨ç‡

```yaml
  - name: resource_alerts
    interval: 30s
    rules:
      # CPU ä½¿ç”¨ç‡è¿‡é«˜
      - alert: HighCPUUsage
        expr: |
          sum(rate(container_cpu_usage_seconds_total{namespace="arbitragex"}[5m])) by (pod)
          /
          sum(container_spec_cpu_quota{namespace="arbitragex"} / container_spec_cpu_period{namespace="arbitragex"}) by (pod) > 0.9
        for: 10m
        labels:
          severity: warning
          level: P2
          category: resource
        annotations:
          summary: "High CPU usage on {{ $labels.pod }}"
          description: "CPU usage is {{ $value | humanizePercentage }}"
```

#### å†…å­˜ä½¿ç”¨ç‡

```yaml
      # å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜
      - alert: HighMemoryUsage
        expr: |
          container_memory_usage_bytes{namespace="arbitragex"}
          /
          container_spec_memory_limit_bytes{namespace="arbitragex"} > 0.9
        for: 10m
        labels:
          severity: warning
          level: P2
          category: resource
        annotations:
          summary: "High memory usage on {{ $labels.pod }}"
          description: "Memory usage is {{ $value | humanizePercentage }}"

      # å†…å­˜ä½¿ç”¨ç‡ä¸¥é‡è¿‡é«˜
      - alert: CriticalHighMemoryUsage
        expr: |
          container_memory_usage_bytes{namespace="arbitragex"}
          /
          container_spec_memory_limit_bytes{namespace="arbitragex"} > 0.95
        for: 5m
        labels:
          severity: critical
          level: P1
          category: resource
        annotations:
          summary: "Critical high memory usage on {{ $labels.pod }}"
          description: "Memory usage is {{ $value | humanizePercentage }}, Pod may OOM soon"
```

#### ç£ç›˜ç©ºé—´

```yaml
      # ç£ç›˜ç©ºé—´ä¸è¶³
      - alert: DiskSpaceLow
        expr: |
          (node_filesystem_avail_bytes{mountpoint="/"}
          /
          node_filesystem_size_bytes{mountpoint="/"}) < 0.1
        for: 10m
        labels:
          severity: warning
          level: P2
          category: resource
        annotations:
          summary: "Disk space low on {{ $labels.instance }}"
          description: "Only {{ $value | humanizePercentage }} disk space available"

      # ç£ç›˜ç©ºé—´ä¸¥é‡ä¸è¶³
      - alert: DiskSpaceCriticallyLow
        expr: |
          (node_filesystem_avail_bytes{mountpoint="/"}
          /
          node_filesystem_size_bytes{mountpoint="/"}) < 0.05
        for: 5m
        labels:
          severity: critical
          level: P0
          category: resource
        annotations:
          summary: "Disk space critically low on {{ $labels.instance }}"
          description: "Only {{ $value | humanizePercentage }} disk space available"
```

### 2.4 ä¸­é—´ä»¶å‘Šè­¦

#### MySQL

```yaml
  - name: middleware_alerts
    interval: 30s
    rules:
      # MySQL è¿æ¥æ•°è¿‡é«˜
      - alert: MySQLTooManyConnections
        expr: |
          mysql_global_status_threads_connected
          /
          mysql_global_status_max_connections > 0.8
        for: 5m
        labels:
          severity: warning
          level: P1
          category: middleware
        annotations:
          summary: "MySQL too many connections"
          description: "MySQL connection usage is {{ $value | humanizePercentage }}"

      # MySQL æ…¢æŸ¥è¯¢è¿‡å¤š
      - alert: MySQLTooManySlowQueries
        expr: |
          rate(mysql_global_status_slow_queries[5m]) > 10
        for: 5m
        labels:
          severity: warning
          level: P2
          category: middleware
        annotations:
          summary: "MySQL too many slow queries"
          description: "Slow query rate is {{ $value }}/s"

      # MySQL å¤åˆ¶å»¶è¿Ÿ
      - alert: MySQLReplicationLag
        expr: |
          mysql_slave_status_seconds_behind_master > 60
        for: 5m
        labels:
          severity: critical
          level: P0
          category: middleware
        annotations:
          summary: "MySQL replication lag"
          description: "MySQL slave is {{ $value }}s behind master"
```

#### Redis

```yaml
      # Redis å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜
      - alert: RedisHighMemoryUsage
        expr: |
          redis_memory_used_bytes
          /
          redis_memory_max_bytes > 0.9
        for: 10m
        labels:
          severity: warning
          level: P2
          category: middleware
        annotations:
          summary: "Redis high memory usage"
          description: "Redis memory usage is {{ $value | humanizePercentage }}"

      # Redis å‘½ä¸­ç‡ä½
      - alert: RedisLowHitRate
        expr: |
          rate(redis_keyspace_hits_total[5m])
          /
          (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m])) < 0.7
        for: 15m
        labels:
          severity: warning
          level: P2
          category: middleware
        annotations:
          summary: "Redis low hit rate"
          description: "Redis cache hit rate is only {{ $value | humanizePercentage }}"
```

### 2.5 å®‰å…¨å‘Šè­¦

```yaml
  - name: security_alerts
    interval: 30s
    rules:
      # å¼‚å¸¸ç™»å½•
      - alert: SuspiciousLogin
        expr: |
          sum(rate(login_attempts_total{status="success"}[5m])) by (ip) > 10
        for: 5m
        labels:
          severity: critical
          level: P0
          category: security
        annotations:
          summary: "Suspicious login activity from {{ $labels.ip }}"
          description: "More than 10 successful logins from same IP in 5 minutes"

      # API å¯†é’¥é”™è¯¯
      - alert: APIKeyAuthenticationFailure
        expr: |
          sum(rate(api_authentication_failures_total[5m])) by (key_id) > 5
        for: 5m
        labels:
          severity: warning
          level: P1
          category: security
        annotations:
          summary: "API key authentication failures"
          description: "API key {{ $labels.key_id }} has {{ $value }} failures/s"
```

---

## 3. å‘Šè­¦è·¯ç”±

### 3.1 è·¯ç”±é…ç½®

```yaml
# alertmanager.yml
route:
  # é»˜è®¤æ¥æ”¶å™¨
  receiver: 'default'

  # åˆ†ç»„ç­‰å¾…æ—¶é—´
  group_wait: 10s

  # åˆ†ç»„é—´éš”æ—¶é—´
  group_interval: 10s

  # é‡å¤å‘Šè­¦ç­‰å¾…æ—¶é—´
  repeat_interval: 12h

  # å­è·¯ç”±
  routes:
    # P0 ç´§æ€¥å‘Šè­¦
    - match:
        severity: critical
        level: P0
      receiver: 'pagerduty-critical'
      continue: true

    # P1 ä¸¥é‡å‘Šè­¦
    - match:
        severity: critical
        level: P1
      receiver: 'slack-critical'
      continue: true

    # P2 è­¦å‘Šå‘Šè­¦
    - match:
        severity: warning
        level: P2
      receiver: 'email-warnings'
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 4h

    # P3 æç¤ºå‘Šè­¦
    - match:
        severity: info
        level: P3
      receiver: 'email-info'
      group_wait: 1h
      repeat_interval: 24h

    # æŒ‰ç±»åˆ«è·¯ç”±
    - match:
        category: application
      receiver: 'team-backend'

    - match:
        category: business
      receiver: 'team-product'

    - match:
        category: resource
      receiver: 'team-ops'

    - match:
        category: security
      receiver: 'team-security'
```

### 3.2 æ¥æ”¶å™¨é…ç½®

```yaml
receivers:
  # ============================================
  # é»˜è®¤æ¥æ”¶å™¨
  # ============================================
  - name: 'default'
    email_configs:
      - to: 'alerts@arbitragex.com'
        from: 'alertmanager@arbitragex.com'
        smarthost: 'smtp.gmail.com:587'
        auth_username: 'alertmanager@arbitragex.com'
        auth_password: '${SMTP_PASSWORD}'

  # ============================================
  # PagerDutyï¼ˆP0 ç´§æ€¥ï¼‰
  # ============================================
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'
        severity: 'critical'

  # ============================================
  # Slackï¼ˆP1 ä¸¥é‡ï¼‰
  # ============================================
  - name: 'slack-critical'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts-critical'
        title: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
        text: |
          *Summary*: {{ .CommonAnnotations.summary }}
          *Description*: {{ .CommonAnnotations.description }}
          *Severity*: {{ .CommonLabels.severity }}
          *Level*: {{ .CommonLabels.level }}

  # ============================================
  # Email è­¦å‘Šï¼ˆP2ï¼‰
  # ============================================
  - name: 'email-warnings'
    email_configs:
      - to: 'ops@arbitragex.com'
        from: 'alerts@arbitragex.com'
        headers:
          Subject: '[WARNING] {{ .GroupLabels.alertname }}'
        html: |
          <html>
          <body>
            <h2>{{ .GroupLabels.alertname }}</h2>
            <p><strong>Summary:</strong> {{ .CommonAnnotations.summary }}</p>
            <p><strong>Description:</strong> {{ .CommonAnnotations.description }}</p>
            <p><strong>Severity:</strong> {{ .CommonLabels.severity }}</p>
            <hr>
            {{ range .Alerts }}
            <p>{{ .StartsAt.Format "2006-01-02 15:04:05" }} - {{ .Annotations.description }}</p>
            {{ end }}
          </body>
          </html>

  # ============================================
  # Email æç¤ºï¼ˆP3ï¼‰
  # ============================================
  - name: 'email-info'
    email_configs:
      - to: 'team@arbitragex.com'
        from: 'alerts@arbitragex.com'
        headers:
          Subject: '[INFO] {{ .GroupLabels.alertname }}'

  # ============================================
  # å›¢é˜Ÿæ¥æ”¶å™¨
  # ============================================
  - name: 'team-backend'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#team-backend'

  - name: 'team-product'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#team-product'

  - name: 'team-ops'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#team-ops'

  - name: 'team-security'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SECURITY_KEY}'
```

---

## 4. å‘Šè­¦æŠ‘åˆ¶

### 4.1 æŠ‘åˆ¶è§„åˆ™

```yaml
# alertmanager.yml
inhibit_rules:
  # å¦‚æœæœåŠ¡å®Œå…¨ä¸‹çº¿ï¼ŒæŠ‘åˆ¶è¯¥æœåŠ¡çš„æ‰€æœ‰å…¶ä»–å‘Šè­¦
  - source_match:
      severity: 'critical'
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '(.*)'
    equal: ['instance']

  # å¦‚æœ Pod è¢«é©±é€ï¼ŒæŠ‘åˆ¶è¯¥ Pod çš„èµ„æºå‘Šè­¦
  - source_match:
      alertname: 'PodEvicted'
    target_match_re:
      alertname: '(HighCPUUsage|HighMemoryUsage)'
    equal: ['pod']

  # å¦‚æœæ•°æ®åº“è¿æ¥å¤±è´¥ï¼ŒæŠ‘åˆ¶åº”ç”¨å±‚çš„é”™è¯¯å‘Šè­¦
  - source_match:
      alertname: 'DatabaseConnectionFailed'
    target_match_re:
      alertname: '(.*)Error'
      category: 'application'

  # å¦‚æœæ•´ä¸ªèŠ‚ç‚¹å®•æœºï¼ŒæŠ‘åˆ¶è¯¥èŠ‚ç‚¹ä¸Šæ‰€æœ‰ Pod çš„å‘Šè­¦
  - source_match:
      alertname: 'NodeDown'
    target_match_re:
      alertname: '(.*)'
    equal: ['node']

  # å¦‚æœæ­£åœ¨è¿›è¡Œéƒ¨ç½²ï¼ŒæŠ‘åˆ¶ç›¸å…³çš„é‡å¯å‘Šè­¦
  - source_match:
      alertname: 'DeploymentInProgress'
    target_match_re:
      alertname: 'ServiceRestartingTooFrequently'
```

### 4.2 é™é»˜è§„åˆ™

**åˆ›å»ºé™é»˜**ï¼ˆé€šè¿‡ APIï¼‰ï¼š
```bash
# é™é»˜ 2 å°æ—¶ï¼ˆç»´æŠ¤çª—å£ï¼‰
curl -X POST http://alertmanager:9093/api/v2/silences \
  -H 'Content-Type: application/json' \
  -d '{
    "matchers": [
      {
        "name": "env",
        "value": "production",
        "isRegex": false
      }
    ],
    "startsAt": "2026-01-07T02:00:00Z",
    "endsAt": "2026-01-07T04:00:00Z",
    "createdBy": "admin",
    "comment": "Scheduled maintenance"
  }'
```

**æŸ¥è¯¢æ´»è·ƒé™é»˜**ï¼š
```bash
curl http://alertmanager:9093/api/v2/silences | jq '.[] | select(.status.state == "active")'
```

**åˆ é™¤é™é»˜**ï¼š
```bash
curl -X DELETE http://alertmanager:9093/api/v2/silence/<silence-id>
```

---

## 5. å‘Šè­¦é€šçŸ¥

### 5.1 é‚®ä»¶é€šçŸ¥

#### æ¨¡æ¿

```html
<!-- email-template.html -->
{{ define "email.default.html" }}
<html>
<body>
  <div style="font-family: Arial, sans-serif;">
    <h2 style="color: {{ if eq .CommonLabels.severity "critical" }}#d9534f{{ else if eq .CommonLabels.severity "warning" }}#f0ad4e{{ else }}#5bc0de{{ end }};">
      {{ if eq .Status "firing" }}ğŸ”¥ FIRING{{ else }}âœ… RESOLVED{{ end }}
    </h2>

    <h3>{{ .GroupLabels.alertname }}</h3>

    <table border="1" cellpadding="5" style="border-collapse: collapse;">
      <tr>
        <td><strong>Summary</strong></td>
        <td>{{ .CommonAnnotations.summary }}</td>
      </tr>
      <tr>
        <td><strong>Description</strong></td>
        <td>{{ .CommonAnnotations.description }}</td>
      </tr>
      <tr>
        <td><strong>Severity</strong></td>
        <td>{{ .CommonLabels.severity }}</td>
      </tr>
      <tr>
        <td><strong>Level</strong></td>
        <td>{{ .CommonLabels.level }}</td>
      </tr>
      <tr>
        <td><strong>Time</strong></td>
        <td>{{ .StartsAt.Format "2006-01-02 15:04:05 MST" }}</td>
      </tr>
    </table>

    {{ if gt (len .Alerts) 1 }}
    <h4>Related Alerts:</h4>
    <ul>
      {{ range .Alerts }}
      <li>{{ .Annotations.description }} ({{ .StartsAt.Format "15:04:05" }})</li>
      {{ end }}
    </ul>
    {{ end }}

    {{ if .CommonAnnotations.runbook_url }}
    <p>
      <a href="{{ .CommonAnnotations.runbook_url }}">ğŸ“– Runbook</a>
    </p>
    {{ end }}

    <hr>
    <p style="color: #999; font-size: 12px;">
      Sent by ArbitrageX Alertmanager
    </p>
  </div>
</body>
</html>
{{ end }}
```

### 5.2 Slack é€šçŸ¥

#### Webhook é…ç½®

```yaml
slack_configs:
  - api_url: '${SLACK_WEBHOOK_URL}'
    channel: '#alerts'
    username: 'Alertmanager'
    icon_emoji: ':warning:'
    title: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
    text: |
      *Summary*: {{ .CommonAnnotations.summary }}
      *Description*: {{ .CommonAnnotations.description }}
      *Severity*: {{ .CommonLabels.severity }}
      *Level*: {{ .CommonLabels.level }}

      {{ range .Alerts }}
      â€¢ {{ .Annotations.description }}
      {{ end }}

      <{{ .ExternalURL | reReplaceAll ".*alertmanager.*" "http://grafana/d/xxx" }}|View Dashboard>
    actions:
      - type: button
        text: 'Acknowledge'
        url: '{{ .ExternalURL }}'
      - type: button
        text: 'Runbook'
        url: '{{ .CommonAnnotations.runbook_url }}'
```

### 5.3 PagerDuty é›†æˆ

```yaml
pagerduty_configs:
  - service_key: '${PAGERDUTY_SERVICE_KEY}'
    description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'
    severity: '{{ if eq .CommonLabels.level "P0" }}critical{{ else if eq .CommonLabels.level "P1" }}error{{ else if eq .CommonLabels.level "P2" }}warning{{ else }}info{{ end }}'
    client: 'ArbitrageX Alertmanager'
    client_url: '{{ .ExternalURL }}'
    details:
      firing: '{{ template "pagerduty.default.instances" .Alerts.Firing }}'
      resolved: '{{ template "pagerduty.default.instances" .Alerts.Resolved }}'
      num_firing: '{{ .Alerts.Firing | len }}'
      num_resolved: '{{ .Alerts.Resolved | len }}'
```

### 5.4 ä¼ä¸šå¾®ä¿¡é€šçŸ¥

```go
// package wechat
package wechat

import (
    "encoding/json"
    "fmt"
    "net/http"
)

type WeChatMessage struct {
    MsgType  string `json:"msgtype"`
    Text     struct {
        Content string `json:"content"`
    } `json:"text"`
}

func SendWeChatAlert(webhookURL string, alert string) error {
    msg := WeChatMessage{
        MsgType: "text",
    }
    msg.Text.Content = fmt.Sprintf("ğŸš¨ %s", alert)

    data, err := json.Marshal(msg)
    if err != nil {
        return err
    }

    resp, err := http.Post(webhookURL, "application/json", bytes.NewBuffer(data))
    if err != nil {
        return err
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusOK {
        return fmt.Errorf("wechat API returned status %d", resp.StatusCode)
    }

    return nil
}
```

---

## 6. åº”æ€¥å“åº”

### 6.1 å“åº”æµç¨‹

```
1. å‘Šè­¦æ¥æ”¶
   â”œâ”€ P0: 5 åˆ†é’Ÿå†…å“åº”
   â”œâ”€ P1: 15 åˆ†é’Ÿå†…å“åº”
   â”œâ”€ P2: 1 å°æ—¶å†…å“åº”
   â””â”€ P3: 1 å¤©å†…å“åº”

2. é—®é¢˜ç¡®è®¤
   â”œâ”€ ç¡®è®¤å‘Šè­¦æœ‰æ•ˆæ€§
   â”œâ”€ è¯„ä¼°å½±å“èŒƒå›´
   â””â”€ ç¡®å®šå“åº”çº§åˆ«

3. åˆæ­¥æ’æŸ¥
   â”œâ”€ æŸ¥çœ‹ç›‘æ§é¢æ¿
   â”œâ”€ æ£€æŸ¥æ—¥å¿—
   â”œâ”€ ç¡®è®¤æ ¹å› 
   â””â”€ åˆ¶å®šä¿®å¤æ–¹æ¡ˆ

4. ä¿®å¤æ‰§è¡Œ
   â”œâ”€ å®æ–½ä¿®å¤æ–¹æ¡ˆ
   â”œâ”€ éªŒè¯ä¿®å¤æ•ˆæœ
   â””â”€ æ¢å¤æœåŠ¡

5. å¤ç›˜æ€»ç»“
   â”œâ”€ ç¼–å†™æ•…éšœæŠ¥å‘Š
   â”œâ”€ ä¼˜åŒ–ç›‘æ§å‘Šè­¦
   â””â”€ å®Œå–„åº”æ€¥é¢„æ¡ˆ
```

### 6.2 Runbook

#### æœåŠ¡ä¸‹çº¿ Runbook

**å‘Šè­¦**: ServiceDown

**ç—‡çŠ¶**:
- æœåŠ¡å®Œå…¨ä¸å¯ç”¨
- API è¿”å› 502/503
- å¥åº·æ£€æŸ¥å¤±è´¥

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥ Pod çŠ¶æ€ï¼š`kubectl get pods -n arbitragex`
2. æŸ¥çœ‹ Pod æ—¥å¿—ï¼š`kubectl logs -f <pod-name> -n arbitragex`
3. æ£€æŸ¥äº‹ä»¶ï¼š`kubectl describe pod <pod-name> -n arbitragex`
4. æ£€æŸ¥èµ„æºï¼š`kubectl top pods -n arbitragex`

**å¯èƒ½åŸå› **:
- OOMï¼ˆå†…å­˜æº¢å‡ºï¼‰
- é…ç½®é”™è¯¯
- ä¾èµ–æœåŠ¡ä¸å¯ç”¨
- ä»£ç  Bug

**ä¿®å¤æ–¹æ¡ˆ**:
- OOMï¼šå¢åŠ å†…å­˜é™åˆ¶æˆ–æ’æŸ¥å†…å­˜æ³„æ¼
- é…ç½®é”™è¯¯ï¼šå›æ»šé…ç½®
- ä¾èµ–ä¸å¯ç”¨ï¼šæ¢å¤ä¾èµ–æœåŠ¡
- ä»£ç  Bugï¼šå›æ»šç‰ˆæœ¬

#### é«˜é”™è¯¯ç‡ Runbook

**å‘Šè­¦**: HighErrorRate

**ç—‡çŠ¶**:
- é”™è¯¯ç‡ > 5%
- API è¿”å›å¤§é‡ 5xx
- ç”¨æˆ·åé¦ˆå¼‚å¸¸

**æ’æŸ¥æ­¥éª¤**:
1. æŸ¥çœ‹é”™è¯¯æ—¥å¿—
2. æ£€æŸ¥æ•°æ®åº“è¿æ¥
3. æ£€æŸ¥å¤–éƒ¨ä¾èµ–
4. åˆ†ææœ€è¿‘çš„ä»£ç å˜æ›´

**ä¿®å¤æ–¹æ¡ˆ**:
- æ•°æ®åº“è¿æ¥å¤±è´¥ï¼šé‡å¯æ•°æ®åº“æˆ–åº”ç”¨
- å¤–éƒ¨ä¾èµ–å¤±è´¥ï¼šåˆ‡æ¢åˆ°å¤‡ç”¨ä¾èµ–
- ä»£ç  Bugï¼šå›æ»šç‰ˆæœ¬æˆ–å‘å¸ƒ hotfix

#### é«˜å»¶è¿Ÿ Runbook

**å‘Šè­¦**: HighLatency

**ç—‡çŠ¶**:
- P99 å»¶è¿Ÿ > 1s
- API å“åº”ç¼“æ…¢
- ç”¨æˆ·åé¦ˆå¡é¡¿

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥æ…¢æŸ¥è¯¢æ—¥å¿—
2. åˆ†ææ€§èƒ½å‰–ææ•°æ®
3. æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
4. æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡

**ä¿®å¤æ–¹æ¡ˆ**:
- æ…¢æŸ¥è¯¢ï¼šä¼˜åŒ–æŸ¥è¯¢æˆ–æ·»åŠ ç´¢å¼•
- ç½‘ç»œå»¶è¿Ÿï¼šä¼˜åŒ–ç½‘ç»œæˆ–ä½¿ç”¨ CDN
- ç¼“å­˜å‘½ä¸­ç‡ä½ï¼šå¢åŠ ç¼“å­˜å®¹é‡æˆ–ä¼˜åŒ–ç¼“å­˜ç­–ç•¥

---

## 7. å®Œæ•´é…ç½®

### 7.1 Prometheus é…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'arbitragex-prod'
    env: 'production'

# å‘Šè­¦è§„åˆ™æ–‡ä»¶
rule_files:
  - '/etc/prometheus/rules/*.yml'

# å‘Šè­¦ç®¡ç†å™¨é…ç½®
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - 'alertmanager:9093'

# é‡‡é›†é…ç½®
scrape_configs:
  - job_name: 'arbitragex'
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - arbitragex
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
```

### 7.2 Alertmanager å®Œæ•´é…ç½®

```yaml
# alertmanager.yml
global:
  resolve_timeout: 5m
  slack_api_url: '${SLACK_WEBHOOK_URL}'

# æ¨¡æ¿
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# è·¯ç”±
route:
  receiver: 'default'
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h

  routes:
    # P0 å‘Šè­¦
    - match:
        level: P0
      receiver: 'pagerduty-critical'
      continue: true

    # P1 å‘Šè­¦
    - match:
        level: P1
      receiver: 'slack-critical'

    # P2 å‘Šè­¦
    - match:
        level: P2
      receiver: 'email-warnings'

    # P3 å‘Šè­¦
    - match:
        level: P3
      receiver: 'email-info'

# æŠ‘åˆ¶è§„åˆ™
inhibit_rules:
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '(.*)'
    equal: ['instance']

# æ¥æ”¶å™¨
receivers:
  - name: 'default'
    email_configs:
      - to: 'alerts@arbitragex.com'
        from: 'alertmanager@arbitragex.com'
        smarthost: 'smtp.gmail.com:587'
        auth_username: 'alertmanager@arbitragex.com'
        auth_password: '${SMTP_PASSWORD}'

  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'

  - name: 'slack-critical'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts-critical'

  - name: 'email-warnings'
    email_configs:
      - to: 'ops@arbitragex.com'
        from: 'alerts@arbitragex.com'

  - name: 'email-info'
    email_configs:
      - to: 'team@arbitragex.com'
```

---

## é™„å½•

### A. ç›¸å…³æ–‡æ¡£

- [README.md](./README.md) - ç›‘æ§å¯¼èˆª
- [Metrics_Design.md](./Metrics_Design.md) - ç›‘æ§æŒ‡æ ‡è®¾è®¡
- [Production_Deployment.md](../Deployment/Production_Deployment.md) - ç”Ÿäº§éƒ¨ç½²

### B. å‘Šè­¦æµ‹è¯•

```bash
# æµ‹è¯•å‘Šè­¦è§„åˆ™
promtool test rules test_alerts.yml

# éªŒè¯ Alertmanager é…ç½®
amtool config check alertmanager.yml

# æµ‹è¯•å‘Šè­¦è·¯ç”±
amtool alert add alertname=Test severity=warning --alertmanager.url=http://localhost:9093
```

### C. æœ€ä½³å®è·µ

1. **å‘Šè­¦æœ‰æ•ˆæ€§**ï¼šæ¯ä¸ªå‘Šè­¦éƒ½åº”è¯¥æœ‰æ˜ç¡®çš„å¤„ç†æµç¨‹
2. **é¿å…å‘Šè­¦ç–²åŠ³**ï¼šåˆç†è®¾ç½®é˜ˆå€¼å’Œç­‰å¾…æ—¶é—´
3. **æä¾›ä¸Šä¸‹æ–‡**ï¼šå‘Šè­¦ä¿¡æ¯åº”è¯¥åŒ…å«è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡
4. **æ–‡æ¡£å®Œå–„**ï¼šä¸ºæ¯ä¸ªå‘Šè­¦ç¼–å†™ Runbook
5. **å®šæœŸå®¡æŸ¥**ï¼šå®šæœŸå®¡æŸ¥å‘Šè­¦è§„åˆ™çš„æœ‰æ•ˆæ€§
6. **æŒç»­ä¼˜åŒ–**ï¼šæ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µä¼˜åŒ–å‘Šè­¦

---

**æœ€åæ›´æ–°**: 2026-01-07
**ç‰ˆæœ¬**: v1.0.0
